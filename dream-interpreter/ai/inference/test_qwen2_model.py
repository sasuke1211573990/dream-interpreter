#!/usr/bin/env python3
"""
æµ‹è¯•Qwen2æ¨¡å‹åŠ è½½
"""
import os
import torch
from transformers import AutoTokenizer, AutoConfig
from transformers import Qwen2ForCausalLM

def test_qwen2_loading():
    """æµ‹è¯•Qwen2æ¨¡å‹åŠ è½½"""
    print("ğŸš€ å¼€å§‹æµ‹è¯•Qwen2æ¨¡å‹åŠ è½½...")
    
    # æœ¬åœ°æ¨¡å‹è·¯å¾„
    model_path = r"C:\Users\ZhuanZ(æ— å¯†ç )\.cache\huggingface\hub\models--deepseek-ai--DeepSeek-R1-Distill-Qwen-7B\snapshots\916b56a44061fd5cd7d6a8fb632557ed4f724f60"
    
    try:
        print(f"ğŸ“ æ¨¡å‹è·¯å¾„: {model_path}")
        
        # æ£€æŸ¥æ¨¡å‹é…ç½®
        print("ğŸ” åŠ è½½æ¨¡å‹é…ç½®...")
        config = AutoConfig.from_pretrained(model_path, trust_remote_code=True, local_files_only=True)
        print(f"âœ… æ¨¡å‹ç±»å‹: {config.model_type}")
        print(f"âœ… æ¨¡å‹æ¶æ„: {config.architectures}")
        
        # åŠ è½½åˆ†è¯å™¨
        print("ğŸ“š åŠ è½½åˆ†è¯å™¨...")
        tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True, local_files_only=True)
        print(f"âœ… åˆ†è¯å™¨åŠ è½½æˆåŠŸ")
        
        # åŠ è½½æ¨¡å‹
        print("ğŸ§  åŠ è½½Qwen2æ¨¡å‹...")
        model = Qwen2ForCausalLM.from_pretrained(
            model_path,
            trust_remote_code=True,
            local_files_only=True,
            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
            device_map="auto" if torch.cuda.is_available() else None,
        )
        
        if not torch.cuda.is_available():
            model = model.to("cpu")
            
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
        
        # ç®€å•æµ‹è¯•
        print("ğŸ§ª è¿›è¡Œæ¨ç†æµ‹è¯•...")
        test_text = "æ¢¦è§è›‡æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ"
        inputs = tokenizer(test_text, return_tensors="pt")
        
        if torch.cuda.is_available():
            inputs = {k: v.cuda() for k, v in inputs.items()}
        
        with torch.no_grad():
            outputs = model.generate(**inputs, max_length=100, num_return_sequences=1)
        
        result = tokenizer.decode(outputs[0], skip_special_tokens=True)
        print(f"ğŸ“ æµ‹è¯•ç»“æœ: {result}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_qwen2_loading()
    if success:
        print("\nğŸ‰ Qwen2æ¨¡å‹åŠ è½½æµ‹è¯•æˆåŠŸ!")
    else:
        print("\nğŸ’¥ Qwen2æ¨¡å‹åŠ è½½æµ‹è¯•å¤±è´¥!")